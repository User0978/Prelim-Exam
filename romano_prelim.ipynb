{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e11cc8b",
   "metadata": {},
   "source": [
    "# Machine Learning Code Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "3956ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries needed\n",
    "import numpy as np              #used for algebra\n",
    "import pandas as pd             #used for reading csv files\n",
    "import matplotlib.pyplot as plt #used to plot the data\n",
    "import seaborn as sns           #used to make statistical graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "38d0487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling and checking the dataset\n",
    "datatrain = pd.read_csv('train.csv')\n",
    "datatrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "a73e50b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used to check if there are empty/null values in the dataset\n",
    "datatrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "79660e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3    male  22.000000      1      0   7.2500        S\n",
       "1           1       1  female  38.000000      1      0  71.2833        C\n",
       "2           1       3  female  26.000000      0      0   7.9250        S\n",
       "3           1       1  female  35.000000      1      0  53.1000        S\n",
       "4           0       3    male  35.000000      0      0   8.0500        S\n",
       "..        ...     ...     ...        ...    ...    ...      ...      ...\n",
       "886         0       2    male  27.000000      0      0  13.0000        S\n",
       "887         1       1  female  19.000000      0      0  30.0000        S\n",
       "888         0       3  female  29.699118      1      2  23.4500        S\n",
       "889         1       1    male  26.000000      0      0  30.0000        C\n",
       "890         0       3    male  32.000000      0      0   7.7500        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning the dataset by dropping unused columns and giving values to some of the empty cells\n",
    "datatrain = datatrain.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "datatrain[\"Age\"].fillna(datatrain[\"Age\"].mean(), inplace=True)\n",
    "datatrain[\"Embarked\"].fillna(\"U\", inplace=True)\n",
    "datatrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "eccbef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing of the data to change the string values to numerical values\n",
    "from sklearn import preprocessing\n",
    "#uses labelencoder to change the labels of each cell in the existing columns into numerical values\n",
    "le = preprocessing.LabelEncoder()\n",
    "cols = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "for col in cols:\n",
    "        datatrain[col] = le.fit_transform(datatrain[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "437a71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the values of X and y based on the independent and dependent variables in the csv file\n",
    "X = datatrain.drop(\"Survived\", axis=1)\n",
    "y = datatrain[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e10c5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the train-test split library and used to split the dataset into the test and train variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "f69cb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries needed to create a model, in this case, I used LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "#defining and fitting the variables into the model\n",
    "LR = LogisticRegression(random_state=42, max_iter=100)\n",
    "LR.fit(X_train,y_train)\n",
    "prediction = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "a3ee45b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the accuracy of the original model\n",
    "pred_acc = accuracy_score(y_test, prediction)\n",
    "pred_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "8df799da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.801493 using {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.799596 with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.799596 with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.800065 with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.799126 with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.799596 with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.799602 with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.800072 with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.800535 with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.801493 with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.800522 with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.800522 with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.794953 with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.724146 with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.724146 with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.710113 with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries used for hyperparameter tuning to determine the best parameters to use\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "#stored the parameters that can be used into arrays to be called later\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "#creates a gridsearch of parameters by testing which parameter will yield the highest accuracy\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=LR, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "#prints the best parameter to use \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#prints the list of parameter combinations with their respective accuracy scores\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"%f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ae182662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#prints the best parameter result of the gridsearch\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "66a91c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#application of the best parameters in the gridsearch to the model and refitting the data\n",
    "LR1 = LogisticRegression(penalty=\"l2\", C=0.1, solver=\"newton-cg\", random_state=42, max_iter=100)\n",
    "LR1.fit(X_train,y_train)\n",
    "prediction_tuned = LR1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "a9b2d4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the predicted accuracy of the tuned model, in this case, the accuracy was the same as the original\n",
    "pred_acc_tuned_LR = accuracy_score(y_test, prediction_tuned)\n",
    "pred_acc_tuned_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "bf7e751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy:  0.8100558659217877\n",
      "Tuned Accuracy:  0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "#comparison between the Original Accuracy and the hyper tuned Accuracy\n",
    "print(\"Original Accuracy: \", pred_acc)\n",
    "print(\"Tuned Accuracy: \", pred_acc_tuned_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "ac36641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the final predicted outcome based on the test csv file using the tuned model since it has the same accuracy as the original one\n",
    "prediction_final_LR = LR1.predict(X_test)\n",
    "prediction_final_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e03fe9",
   "metadata": {},
   "source": [
    "# Machine Learning Code Using K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "afe50764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries needed\n",
    "import numpy as np              #used for algebra\n",
    "import pandas as pd             #used for reading csv files\n",
    "import matplotlib.pyplot as plt #used to plot the data\n",
    "import seaborn as sns           #used to make statistical graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c734bbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling and checking the dataset\n",
    "datatrain = pd.read_csv('train.csv')\n",
    "datatrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "10da519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used to check if there are empty/null values in the dataset\n",
    "datatrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "78774349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3    male  22.000000      1      0   7.2500        S\n",
       "1           1       1  female  38.000000      1      0  71.2833        C\n",
       "2           1       3  female  26.000000      0      0   7.9250        S\n",
       "3           1       1  female  35.000000      1      0  53.1000        S\n",
       "4           0       3    male  35.000000      0      0   8.0500        S\n",
       "..        ...     ...     ...        ...    ...    ...      ...      ...\n",
       "886         0       2    male  27.000000      0      0  13.0000        S\n",
       "887         1       1  female  19.000000      0      0  30.0000        S\n",
       "888         0       3  female  29.699118      1      2  23.4500        S\n",
       "889         1       1    male  26.000000      0      0  30.0000        C\n",
       "890         0       3    male  32.000000      0      0   7.7500        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning the dataset by dropping unused columns and giving values to some of the empty cells\n",
    "datatrain = datatrain.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "datatrain[\"Age\"].fillna(datatrain[\"Age\"].mean(), inplace=True)\n",
    "datatrain[\"Embarked\"].fillna(\"U\", inplace=True)\n",
    "datatrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "67b00834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing of the data to change the string values to numerical values\n",
    "from sklearn import preprocessing\n",
    "#uses labelencoder to change the labels of each cell in the existing columns into numerical values\n",
    "le = preprocessing.LabelEncoder()\n",
    "cols = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "for col in cols:\n",
    "        datatrain[col] = le.fit_transform(datatrain[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "8de5fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the values of X and y based on the independent and dependent variables in the csv file\n",
    "X = datatrain.drop(\"Survived\", axis=1)\n",
    "y = datatrain[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "12857747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the train-test split library and used to split the dataset into the test and train variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "53ccef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the preprocessing library for standardscaler to use in the KNN Classifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#This standardizes the data and scales it to the unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "c390c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries needed to create a model, in this case, I used K-Nearest Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#defining and fitting the variables into the model\n",
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(X_train, y_train)\n",
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "73ef8f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212290502793296"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the accuracy of the original model\n",
    "pred_acc = accuracy_score(y_test, prediction)\n",
    "pred_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "5cbf930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.822105 using {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "0.746668 with: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.746668 with: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.788778 with: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.782251 with: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.796753 with: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.793936 with: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.800033 with: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.796283 with: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.807544 with: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.799544 with: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "0.811783 with: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.791608 with: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.816934 with: {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "0.795351 with: {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "0.816478 with: {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.796290 with: {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.818349 with: {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'uniform'}\n",
      "0.797235 with: {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "0.810850 with: {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.795833 with: {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "0.750385 with: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.750385 with: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.799550 with: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.785518 with: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.797261 with: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.784122 with: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.799589 with: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.793486 with: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.808046 with: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.798650 with: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "0.819744 with: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.798168 with: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.822105 with: {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "0.799596 with: {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "0.819764 with: {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.798187 with: {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.819301 with: {'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'uniform'}\n",
      "0.797737 with: {'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "0.817860 with: {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.797718 with: {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "0.746668 with: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.746668 with: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.788778 with: {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.782251 with: {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.796753 with: {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.793936 with: {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.800033 with: {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.796283 with: {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.807544 with: {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.799544 with: {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "0.811783 with: {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.791608 with: {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.816934 with: {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "0.795351 with: {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "0.816478 with: {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.796290 with: {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.818349 with: {'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'uniform'}\n",
      "0.797235 with: {'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "0.810850 with: {'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.795833 with: {'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries used for hyperparameter tuning to determine the best parameters to use\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "#stored the parameters that can be used into arrays to be called later\n",
    "n_neighbors = range(1, 21, 2)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "#creates a gridsearch of parameters by testing which parameter will yield the highest accuracy\n",
    "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "#prints the best parameter to use \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#prints the list of parameter combinations with their respective accuracy scores\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"%f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "a889bbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#prints the best parameter result of the gridsearch\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "32e10796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#application of the best parameters in the gridsearch to the model and refitting the data\n",
    "classifier1 = KNeighborsClassifier(n_neighbors=13, weights=\"uniform\", metric=\"manhattan\")\n",
    "classifier1.fit(X_train, y_train)\n",
    "prediction_tuned = classifier1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "79a910a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8324022346368715"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the predicted accuracy of the tuned model, in this case, the accuracy became higher than the original parameters\n",
    "pred_acc_tuned_KNN = accuracy_score(y_test, prediction_tuned)\n",
    "pred_acc_tuned_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "816eb823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy:  0.8212290502793296\n",
      "Tuned Accuracy:  0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "#comparison between the Original Accuracy and the hyper tuned Accuracy\n",
    "print(\"Original Accuracy: \", pred_acc)\n",
    "print(\"Tuned Accuracy: \", pred_acc_tuned_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "b034ce40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the final predicted outcome based on the tuned prediction since the accuracy increased by around 1%\n",
    "prediction_final_KNN = classifier1.predict(X_test)\n",
    "prediction_final_KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990bacca",
   "metadata": {},
   "source": [
    "# Neural Network Code Using MLP in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "dec95b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries needed\n",
    "import numpy as np              #used for algebra\n",
    "import pandas as pd             #used for reading csv files\n",
    "import matplotlib.pyplot as plt #used to plot the data\n",
    "import seaborn as sns           #used to make statistical graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "f81921f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling and checking the dataset\n",
    "datatrain = pd.read_csv('train.csv')\n",
    "datatrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "79eafdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used to check if there are empty/null values in the dataset\n",
    "datatrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "447035e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0           0       3    male  22.000000      1      0   7.2500        S\n",
       "1           1       1  female  38.000000      1      0  71.2833        C\n",
       "2           1       3  female  26.000000      0      0   7.9250        S\n",
       "3           1       1  female  35.000000      1      0  53.1000        S\n",
       "4           0       3    male  35.000000      0      0   8.0500        S\n",
       "..        ...     ...     ...        ...    ...    ...      ...      ...\n",
       "886         0       2    male  27.000000      0      0  13.0000        S\n",
       "887         1       1  female  19.000000      0      0  30.0000        S\n",
       "888         0       3  female  29.699118      1      2  23.4500        S\n",
       "889         1       1    male  26.000000      0      0  30.0000        C\n",
       "890         0       3    male  32.000000      0      0   7.7500        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning the dataset by dropping unused columns and giving values to some of the empty cells\n",
    "datatrain = datatrain.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "datatrain[\"Age\"].fillna(datatrain[\"Age\"].mean(), inplace=True)\n",
    "datatrain[\"Embarked\"].fillna(\"U\", inplace=True)\n",
    "datatrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "06933b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing of the data to change the string values to numerical values\n",
    "from sklearn import preprocessing\n",
    "#uses labelencoder to change the labels of each cell in the existing columns into numerical values\n",
    "le = preprocessing.LabelEncoder()\n",
    "cols = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "for col in cols:\n",
    "        datatrain[col] = le.fit_transform(datatrain[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "6b7d86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the values of X and y based on the independent and dependent variables in the csv file\n",
    "X = datatrain.drop(\"Survived\", axis=1)\n",
    "y = datatrain[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "d66709bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the train-test split library and used to split the dataset into the test and train variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "afa94c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries needed to create a model, in this case, I used MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#defining and fitting the variables into the model\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "prediction = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "586a027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7653631284916201"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the accuracy of the original model\n",
    "pred_acc = accuracy_score(y_test, prediction)\n",
    "pred_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "6426bcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.803339 using {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.799596 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.704969 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.788328 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.799596 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.563322 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.788328 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.799596 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.749961 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.788328 with: {'activation': 'identity', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.803339 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.666197 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.708685 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.803339 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.623592 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.708685 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.803339 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.667123 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.708685 with: {'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.794412 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.681605 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.700280 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.794412 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.645149 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.700280 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.794412 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.683014 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.700280 with: {'activation': 'tanh', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.798239 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'lbfgs'}\n",
      "0.677400 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.747600 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "0.798239 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'lbfgs'}\n",
      "0.383914 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'sgd'}\n",
      "0.747600 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
      "0.798239 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n",
      "0.677393 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "0.747600 with: {'activation': 'relu', 'hidden_layer_sizes': [5], 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries used for hyperparameter tuning to determine the best parameters to use\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "#stored the parameters that can be used into arrays to be called later\n",
    "hidden_layer_sizes = [5],\n",
    "activation = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "solver = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "learning_rate = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "#creates a gridsearch of parameters by testing which parameter will yield the highest accuracy\n",
    "grid = dict(hidden_layer_sizes=hidden_layer_sizes,activation=activation,solver=solver,learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "#prints the best parameter to use \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "#prints the list of parameter combinations with their respective accuracy scores\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"%f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "13e0caa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'logistic', 'hidden_layer_sizes': [5], 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#prints the best parameter result of the gridsearch\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "f461c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#application of the best parameters in the gridsearch to the model and refitting the data\n",
    "mlp1 = MLPClassifier(activation=\"logistic\", hidden_layer_sizes=5, learning_rate=\"constant\", solver=\"adam\",random_state=42, max_iter=1000)\n",
    "mlp1.fit(X_train, y_train)\n",
    "prediction_tuned = mlp1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "25e9969b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7821229050279329"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the predicted accuracy of the tuned model, in this case, the accuracy became higher than the original parameters\n",
    "pred_acc_tuned_MLP = accuracy_score(y_test, prediction_tuned)\n",
    "pred_acc_tuned_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "4e13990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy:  0.7653631284916201\n",
      "Tuned Accuracy:  0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "#comparison between the Original Accuracy and the hyper tuned Accuracy\n",
    "print(\"Original Accuracy: \", pred_acc)\n",
    "print(\"Tuned Accuracy: \", pred_acc_tuned_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f4e85ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints the final predicted outcome based on the tuned prediction since the accuracy increased by around 2%\n",
    "prediction_final_MLP = mlp1.predict(X_test)\n",
    "prediction_final_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b28ed43",
   "metadata": {},
   "source": [
    "# Comparison, Analysis and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e4a62",
   "metadata": {},
   "source": [
    "Data Comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8022e5f",
   "metadata": {},
   "source": [
    "Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "daf1e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.8100558659217877 \n",
      "K-Nearest Neighbors Accuracy:  0.8324022346368715 \n",
      "MultiLayer Perceptron Accuracy:  0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Accuracy: \",pred_acc_tuned_LR, \"\\n\" \"K-Nearest Neighbors Accuracy: \",pred_acc_tuned_KNN, \"\\n\" \"MultiLayer Perceptron Accuracy: \",pred_acc_tuned_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389ee50",
   "metadata": {},
   "source": [
    "Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "fdf3422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction:\n",
      " [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Prediction:\\n\",prediction_final_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "5d447034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Prediction:\n",
      " [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Nearest Neighbors Prediction:\\n\",prediction_final_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "092e4e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayer Perceptron Prediction:\n",
      " [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"MultiLayer Perceptron Prediction:\\n\",prediction_final_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0aeab",
   "metadata": {},
   "source": [
    "Analysis and Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15362572",
   "metadata": {},
   "source": [
    "Based on the models that I used, I found Logical Regression to be the easiest to use and straightforward. The hardest one was the MultiLayer Perceptron Neural Network since it required me to research a lot of syntax that I didn't know before. However, after a long grind since the first day, I managed to comeplete it with a reasonable accuracy. Upon comparing the three models, I saw that the K-Nearest Neighbors had the highest accuracy, maybe because the data that I used in the data processing can be easily classified and I removed the ones with null cells. Both the LR and KNN had an accuracy of more than 80% after hyperparameter tuning and MLP came close to 80% after the hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d7f0c",
   "metadata": {},
   "source": [
    "Upon looking on the prediction arrays, the three models predicted almost the same in most of the cells. With this, I can conclude that whatever factor that was, It was a common reason why and how the person survived and how some died. Although we cannot guarantee this since the accuracy is not 100%, we can assume some of these can be true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a134c94",
   "metadata": {},
   "source": [
    "Based on this coding experience, I gained a lot of knowledge in neural networks especially in tensorflow, however, I could not use this knowledge since the tensorflow neural networks mostly focused on image processing. This also gave me ideas on how to process my data, for example, in the titanic dataset, I could use the Cabin data and determine if there was a correlation between survival and having a cabin, since a lot of the time you will be located in the Cabin, however, I could not implement this since I did not know how to process the data and make it work that way. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
